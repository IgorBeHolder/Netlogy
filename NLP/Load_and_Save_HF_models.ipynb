{"cells":[{"cell_type":"markdown","metadata":{"id":"xbTrJ2KJKTNF"},"source":["## Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7999,"status":"ok","timestamp":1696414944933,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"ajzt9P1-DC-n"},"outputs":[],"source":["!pip install -q ctransformers>=0.2.24"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reinstall ctransformers with metal\n","!pip uninstall ctransformers --yes \n","!CT_METAL=1 pip install ctransformers --no-binary ctransformers"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5552,"status":"ok","timestamp":1696414950482,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"qse7fMVCJscI"},"outputs":[],"source":["!pip3 install -q huggingface-hub>=0.17.1\n","# !pip list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1696414952483,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"yeTTdyXOKOmK"},"outputs":[],"source":["from ctransformers import AutoModelForCausalLM"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1696414959820,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"jtf5IOmBL79V"},"outputs":[],"source":["import time\n","\n","def measure_runtime(func):\n","    def wrapper(*args, **kwargs):\n","        start_time = time.time()\n","        result = func(*args, **kwargs)\n","        end_time = time.time()\n","        duration = end_time - start_time\n","        print(f\"Function {func.__name__} executed in {duration:.4f} seconds\\n\")\n","        return result\n","    return wrapper\n","\n","def model_config(model):\n","    print(model.model_path)\n","    print (model.config)\n","    print(model.model_type)\n","    print(model.context_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1696414963888,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"3VLJFy9TMO61"},"outputs":[],"source":["prompts = [\"What is the capital of Sweden?\",\n","           \"Какой город является столицей Швеции?\",\n","           \"Почему люди предпочитают весну?\",\n","           \"Why people prefer spring?\",\n","           \"AI is going to\",\n","           \"Напиши рецепт лазаньи?\",\n","           \"Что такое python\",\n","           \"Белые медведи и пингвины могут встречаться вместе в природе?\",\n","           \"Is modest wine drinking not harmful for our health?\"\n","\n","           ]\n","\n","@measure_runtime\n","def printout_prompt(model, prompt):\n","    print(f'{\"-\"*80}\\nThe prompt: {prompt}\\n')\n","    print(f'The ({model.model_path }) model answer is:\\n')\n","    print(model(prompt))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oD4lJ7PjKdWK"},"source":["### TheBloke/Llama-2-7b-Chat-GGUF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33293,"status":"ok","timestamp":1696415310405,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"86qPxMYPXjgF","outputId":"57dfcf98-5786-4c37-dff1-305568c07764"},"outputs":[],"source":["# !huggingface-cli download TheBloke/Llama-2-7b-Chat-GGUF --local-dir . --local-dir-use-symlinks False --include='*Q4_K_M.gguf'\n","\n","!huggingface-cli download TheBloke/Llama-2-7b-Chat-GGUF llama-2-7b-chat.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1571,"status":"ok","timestamp":1696415218149,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"biJin6PET9yX"},"outputs":[],"source":["# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n","llm_7chat = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id=\"/Users/velo1/SynologyDrive/GIT_syno/data/NLP/models/\", model_file=\"llama-2-7b-chat.Q4_K_M.gguf\", \\\n","                                           model_type=\"llama\", gpu_layers=0, local_files_only=True\n","\n","\n","\n","                                                 )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check the path\n","import os\n","\n","model_path = \"/Users/velo1/SynologyDrive/GIT_syno/data/NLP/models/llama-2-7b-chat.Q4_K_M.gguf\"\n","if os.path.exists(model_path):\n","    print(\"Path exists!\")\n","else:\n","    print(\"Path does not exist. Check the path.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":702789,"status":"ok","timestamp":1696399655968,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"kHJutbn8lwNt","outputId":"601acdc4-2b0c-43c7-965c-1bf61fff7020"},"outputs":[],"source":["for prompt in prompts:\n","    printout_prompt(model=llm_7chat, prompt=prompt)\n"]},{"cell_type":"markdown","metadata":{"id":"BEdA2SXhLFcc"},"source":["### rozek/LLaMA-2-7B-32K-Instruct_GGUF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21192,"status":"ok","timestamp":1696415164724,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"UtQA27bIYhI_","outputId":"871f5bba-1ed3-455a-d03b-7aea0f4af5f7"},"outputs":[],"source":["!huggingface-cli download rozek/LLaMA-2-7B-32K-Instruct_GGUF LLaMA-2-7B-32K-Instruct-Q8_0.gguf --local-dir . --local-dir-use-symlinks False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3641,"status":"ok","timestamp":1696407544329,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"n0QMEdLRcyt6","outputId":"71d3335f-3c35-4b82-af97-db6bb555f6ac"},"outputs":[],"source":["%%time\n","# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n","llm_7_32 = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id=\"/content/\", model_file=\"LLaMA-2-7B-32K-Instruct-Q8_0.gguf\", \\\n","                                           model_type=\"llama\", gpu_layers=0, local_files_only=True,\\\n","                                              batch_size=4096,\n","                                              temperature = 0.4\n","\n","\n","\n","                                                )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":937276,"status":"ok","timestamp":1696400972913,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"eFV7rue2S9dQ","outputId":"9045e4a1-f987-4cda-d785-6a125f436591"},"outputs":[],"source":["for prompt in prompts:\n","    printout_prompt(model=llm_7_32, prompt=prompt)"]},{"cell_type":"markdown","metadata":{"id":"zG2EapEaTJdf"},"source":["### TheBloke/OpenBuddy-Llama2-13B-v11.1-GGUF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66282,"status":"ok","timestamp":1696415083099,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"QnbQTCx_MJkC","outputId":"29edb45c-d284-4e2b-e447-e2dd971d6b94"},"outputs":[],"source":["!huggingface-cli download TheBloke/OpenBuddy-Llama2-13B-v11.1-GGUF openbuddy-llama2-13b-v11.1.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1696415087845,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"PVweCLxpM9KJ","outputId":"1ab8408d-c4f2-4a7b-8498-48290a030df0"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1696415320151,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"DH8UrDA1GoN6","outputId":"397408b8-4458-4297-a621-f1bfaa463ec6"},"outputs":[],"source":["%%time\n","# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n","llm_13 = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id=\"/content/\", model_file=\"openbuddy-llama2-13b-v11.1.Q4_K_M.gguf\", \\\n","                                           model_type=\"llama\", gpu_layers=30, local_files_only=True,\n","                                              max_new_tokens=100,\n","                                            #   top_k=50,\n","                                            #   top_p =1,\n","                                            #   batch_size=1024,\n","                                            #   temperature = 0.7\n","                                              )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"elapsed":30159,"status":"error","timestamp":1696415420361,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"leFa7hhiTSw-","outputId":"9dd27826-e9d8-4a6c-a830-0e3b0655f124"},"outputs":[],"source":["for prompt in prompts:\n","    printout_prompt(model=llm_7chat, prompt=prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":204723,"status":"error","timestamp":1696414570937,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"HIvatlHYJE9H","outputId":"79d61497-3422-4556-9380-49728ffdc432"},"outputs":[],"source":["for prompt in prompts:\n","    printout_prompt(model=llm_13, prompt=prompt)"]},{"cell_type":"markdown","metadata":{"id":"JPWrfiown_uO"},"source":["## tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1557,"status":"ok","timestamp":1696415444072,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"tsYJmtZUoCfD","outputId":"c3e36384-7a8d-435d-f2af-c2e1095c71a4"},"outputs":[],"source":["%%time\n","llm_7chat = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id=\"/content/\", model_file=\"llama-2-7b-chat.Q4_K_M.gguf\", \\\n","                                                                                      model_type=\"llama\", gpu_layers=0, local_files_only=True,\\\n","                                              max_new_tokens=50,\n","                                              top_k=5,\n","                                              top_p =1,\n","                                              batch_size=1024,\n","                                              temperature = 0.4\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12629,"status":"ok","timestamp":1696412492163,"user":{"displayName":"Igor Sorochan","userId":"03601856735726836276"},"user_tz":-180},"id":"UCQ6bvxmaMhR","outputId":"1c8f798d-1b18-4e4c-b673-13e67d788933"},"outputs":[],"source":["%%time\n","model_ = llm_7chat\n","# model_ = llm_7_32\n","# model_ = llm_13\n","\n","# print(model_(\"Как приготовить суп?\"))\n","print(model_(\"What is the capital of Sweden?\"))\n","# print(model_(\"Why people prefer spring?\"))\n","# print(model_(\"Какой город является столицей Швеции?\"))\n","# print(model_(\"Какие основные ингридиенты в лазанье?\"))\n","model_config(model_)\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","import pathlib\n","from beholder import print_methods\n","import os\n"]},{"cell_type":"markdown","metadata":{},"source":["### Download the model"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["sentence-transformers/all-MiniLM-L6-v2 is found on the local device\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-15 09:33:47.517390: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n","dest_folder = pathlib.Path(\"data/llm_models\")\n","\n","# Split the model_name using the slash\n","parts = model_name.split(\"/\")\n","\n","# If there's a slash in the model_name, use the parts to determine subfolder and model folder\n","if len(parts) > 1:\n","    subfolder, model_folder = parts[0], parts[1]\n","    model_path = dest_folder / subfolder / model_folder\n","else:\n","    subfolder = ''\n","    model_path = dest_folder / model_name\n","\n","# Check if the model exists\n","if model_path.exists():\n","    print(f\"{model_name} is found on the local device\")\n","    model = SentenceTransformer(str(model_path), ma)\n","else:\n","    model = SentenceTransformer(model_name)\n","    model.save(path=str(model_path))\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# ?model"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(2, 384) 1000\n"]}],"source":["sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n","\n","\n","# model = SentenceTransformer(model_name)\n","embeddings = model.encode(sentences)\n","\n","print(embeddings.shape,model.max_seq_length)\n"]},{"cell_type":"markdown","metadata":{},"source":["[model.max_seq_leng](https://stackoverflow.com/questions/75901231/max-seq-length-for-transformer-sentence-bert)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["model.max_seq_length=512"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["512"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model.get_max_seq_length()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP/lr9XEv/imc4yYXKUhS3a","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
