{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[original code](https://sharetext.me/vbn33yx45g)  \n",
    "\n",
    "[article](https://towardsdatascience.com/housing-rental-market-in-germany-exploratory-data-analysis-with-python-3975428d07d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import bs4 as bs  # pip3 install beautifulsoup4 lxml\n",
    "from selenium import webdriver\n",
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "from multiprocessing import Process\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "base_url = \"https://www.immobilienscout24.de\"\n",
    "\n",
    "# Sort=4: price low first\n",
    "# Berlin (East): 178 pages\n",
    "url_berlin = \"https://www.immobilienscout24.de/Suche/de/berlin/berlin/wohnung-mieten?sorting=4&pagenumber=\"\n",
    "# Dresden (East): 72 pages\n",
    "url_dresden = \"https://www.immobilienscout24.de/Suche/de/sachsen/dresden/wohnung-mieten?sorting=4&&pagenumber=\"\n",
    "# Munchen (South): 90 pages\n",
    "url_munchen = \"https://www.immobilienscout24.de/Suche/de/bayern/muenchen/wohnung-mieten?sorting=4&pagenumber=\"\n",
    "# Frankfurt (Center): 90 pages\n",
    "url_frankfurt = \"https://www.immobilienscout24.de/Suche/de/hessen/frankfurt-am-main/wohnung-mieten?sorting=4&pagenumber=\"\n",
    "# Koeln (West): 55 pages\n",
    "url_koeln = \"https://www.immobilienscout24.de/Suche/de/nordrhein-westfalen/koeln/wohnung-mieten?sorting=4&pagenumber=\"\n",
    "# Hamburg (North): 62 pages\n",
    "url_hamburg = \"https://www.immobilienscout24.de/Suche/de/hamburg/hamburg/wohnung-mieten?sorting=4&pagenumber=\"\n",
    "\n",
    "\n",
    "def page_has_loaded(driver: webdriver.Chrome):\n",
    "    \"\"\" Check if the page is ready \"\"\"\n",
    "    page_state = driver.execute_script('return document.readyState;')\n",
    "    return page_state == 'complete'\n",
    "\n",
    "\n",
    "def page_get(url: str, driver: webdriver.Chrome, delay_sec=1.0, cookies: List=[]):\n",
    "    \"\"\" Get the page content \"\"\"\n",
    "    driver.get(url)\n",
    "    time.sleep(delay_sec)\n",
    "    while not page_has_loaded(driver):\n",
    "        time.sleep(1)\n",
    "\n",
    "    return driver.page_source\n",
    "\n",
    "\n",
    "def page_save(file_name: str, body: str):\n",
    "    # with open(file_name, \"w\") as fileToWrite:\n",
    "    #     fileToWrite.write(body)\n",
    "    #     print(f\"{len(body)} bytes saved to {file_name}\")\n",
    "\n",
    "    fileToWrite = open(file_name, \"w\")\n",
    "    fileToWrite.write(body)\n",
    "    fileToWrite.close()\n",
    "    print(f\"{len(body)} bytes saved to {file_name}\")\n",
    "\n",
    "\n",
    "def get_data(city_name: str, city_url: str, start_page: int, end_page: int):\n",
    "    # Chromedriver:\n",
    "    # google-chrome --version\n",
    "    # https://chromedriver.chromium.org/downloads\n",
    "\n",
    "    page_num = start_page\n",
    "\n",
    "    csv_log_lines = []\n",
    "\n",
    "    print(f\"Processing the city: {city_name}, pages {start_page}-{end_page}\")\n",
    "\n",
    "    # Restart with new options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "    # options.add_experimental_option(\"prefs\", prefs)\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver\", chrome_options=options)\n",
    "    page_get(url_berlin, driver, delay_sec=30, cookies=[])\n",
    "    cookies = driver.get_cookies()\n",
    "\n",
    "    while True:\n",
    "        page_url = city_url if page_num == 1 else city_url + str(page_num)\n",
    "        print(\"Parsing page:\", page_url)\n",
    "        # if page_num == 1:\n",
    "        #     print(\"Confirm the check before loading the first page...\")\n",
    "        links = []\n",
    "        for _ in range(5):\n",
    "            delay = 5  # 20 if page_num == 1 else 5\n",
    "            html_data = page_get(page_url, driver, delay_sec=delay, cookies=cookies)\n",
    "            # page_save(f\"data/{city_name}/{city_name}_page_{page_num}.html\", html_data)\n",
    "            # Parse apartments on that page\n",
    "            links = get_page_links(html_data)\n",
    "            if links is not None:\n",
    "                break\n",
    "\n",
    "        # print(\"Links:\", len(links))\n",
    "        for link in links:\n",
    "            print(\"  Parsing:\", link)\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    # Get the page from browser\n",
    "                    html_apartment = page_get(link, driver, delay_sec=0.5, cookies=cookies)\n",
    "\n",
    "                    apt_data = parse_apartment(html_apartment)\n",
    "                    apt_data.city = city_name\n",
    "                    print(\"    \", apt_data.to_csv())\n",
    "                    csv_log_lines.append(apt_data.to_csv())\n",
    "                    break\n",
    "                except:\n",
    "                    print(\"Cannot parse data, try again after 10s\")\n",
    "                    time.sleep(10)\n",
    "\n",
    "            # Save for local testing\n",
    "            # page_save(f\"data/{city_name}/{city_name}_apartment_{item_id}.html\", html_apartment)\n",
    "            # time.sleep(0.5)\n",
    "\n",
    "        if len(links) == 0:\n",
    "            break\n",
    "\n",
    "        # save_log(csv_log_lines, city_name, page_num)\n",
    "        page_num += 1\n",
    "        if page_num >= end_page:\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Save log to file\n",
    "    if len(csv_log_lines) > 0:\n",
    "        save_log(csv_log_lines, city_name, page=f\"{start_page:03d}-{end_page-1:03d}\", header=start_page == 1)\n",
    "\n",
    "\n",
    "def get_page_links(s_html: str) -> Optional[List]:\n",
    "    \"\"\" Parse page with search results \"\"\"\n",
    "    try:\n",
    "        soup = bs.BeautifulSoup(s_html, \"lxml\")\n",
    "        # r = soup.find(\"div\", {\"id\": \"listings\"})\n",
    "        li = soup.find(id=\"resultListItems\")\n",
    "        # children = li.findChildren(\"li\", {\"class\": \"result-list__listing result-list__listing--xl\"}, recursive=False)\n",
    "        children = li.find_all(\"li\", {\"class\": \"result-list__listing\"})\n",
    "        # print(\"Links found:\", len(children))\n",
    "        links_all = []\n",
    "        for child in children:\n",
    "            for link in child.find_all(\"a\"):\n",
    "                # print(\"  \", link.attrs)\n",
    "                if 'data-go-to-expose-id' in link.attrs:\n",
    "                    # print(f\"  {base_url}{link['href']}\")\n",
    "                    links_all.append(base_url + link['href'])\n",
    "                    break\n",
    "        return links_all\n",
    "    except Exception as e:\n",
    "        print(\"get_page_links error:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def value_from_str_float(price_str: str) -> Optional[float]:\n",
    "    \"\"\" Convert string price like \"7.935,60 EUR\" to 7936 \"\"\"\n",
    "    try:\n",
    "        s_filtered = ''.join(c for c in price_str if c in \"0123456789,.\")\n",
    "        # 7.935,60 => 7935.60\n",
    "        return float(s_filtered.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "    except ValueError as _:\n",
    "        # print(\"value_from_str warning: cannot parse str:\", price_str)\n",
    "        return None\n",
    "\n",
    "\n",
    "def value_from_str(price_str: str) -> Optional[int]:\n",
    "    \"\"\" Convert string price like \"7.935,60 EUR\" to 7936 \"\"\"\n",
    "    try:\n",
    "        # 7.935,60 => 7935.60 => 7936\n",
    "        return int(round(value_from_str_float(price_str)))\n",
    "    except ValueError as _:\n",
    "        return None\n",
    "    except TypeError as __:\n",
    "        return None\n",
    "\n",
    "\n",
    "def str_to_csv(data_str: Optional[str]) -> Optional[str]:\n",
    "    \"\"\" Remove \";\" from string \"\"\"\n",
    "    if data_str is not None:\n",
    "        return data_str.replace(';', ' ').replace('\\n', ' ').strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_log_date() -> str:\n",
    "    \"\"\" Use current date as a logging date \"\"\"\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def save_log(log_data: List, city: str, page: str, header=False):\n",
    "    \"\"\" Save log to file \"\"\"\n",
    "    log_filename = f'{city}_{page}.csv'\n",
    "    print(f\"Saving log to {log_filename}\")\n",
    "\n",
    "    with open(log_filename, \"a\", encoding=\"utf-8\") as f_log:\n",
    "        if header:\n",
    "            f_log.write(Apartment.get_header() + \"\\n\")\n",
    "        for log_str in log_data:\n",
    "            f_log.write(log_str + \"\\n\")\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class Apartment:\n",
    "    apt_id: int = 0\n",
    "    apt_type: Optional[str] = None\n",
    "    publisher: str = \"\"\n",
    "    title: str = \"\"\n",
    "    city: Optional[str] = None\n",
    "    address: Optional[str] = None\n",
    "    region: Optional[str] = None\n",
    "    price_cold: Optional[int] = None\n",
    "    price_warm: Optional[int] = None\n",
    "    deposit: Optional[str] = None\n",
    "    area: Optional[float] = None\n",
    "    rooms: Optional[float] = None\n",
    "    floor: Optional[int] = None\n",
    "    floor_max: Optional[int] = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_header():\n",
    "        return (\n",
    "                \"property_id;logging_date;\"\n",
    "                \"property_area;num_rooms;floor;floors_in_building;\"\n",
    "                \"price_cold_eur;price_warm_eur;deposit_eur;property_type;\"\n",
    "                \"publisher;city;title;address;region;\"\n",
    "                )\n",
    "\n",
    "    def to_csv(self):\n",
    "        \"\"\" Convert data to CSV\"\"\"\n",
    "        return (\n",
    "                f\"{self.apt_id};{get_log_date()};\"\n",
    "                f\"{self.area};{self.rooms};{self.floor};{self.floor_max};\"\n",
    "                f\"{self.price_cold};{self.price_warm};{self.deposit};{self.apt_type};\"\n",
    "                f\"{str_to_csv(self.publisher)};{self.city};{str_to_csv(self.title)};{str_to_csv(self.address)};{str_to_csv(self.region)};\"\n",
    "                ) # str_to_csv removes \";\" from string to avoid CSV errors\n",
    "\n",
    "\n",
    "def parse_apartment(s_html: str):\n",
    "    soup = bs.BeautifulSoup(s_html, \"lxml\")\n",
    "    result = Apartment()\n",
    "\n",
    "    # ID\n",
    "    div_id = soup.find(\"div\", {\"class\": \"is24-scoutid\"})\n",
    "    if div_id is not None:\n",
    "        item_id = re.search(r\"Scout-ID:\\s*[0-9]*\", div_id.get_text())\n",
    "        if item_id is not None:\n",
    "            # \" Scout-ID: 140609619 \" => [\"Scout-ID\", \"140609619\"] => \"140609619\"\n",
    "            result.apt_id = item_id.group(0).split(' ')[1]\n",
    "            # print(\"ID:\", result.apt_id)\n",
    "\n",
    "    # Title\n",
    "    title = soup.find_all(\"h1\", id=\"expose-title\")\n",
    "    if len(title) > 0:\n",
    "        result.title = title[0].get_text().strip()\n",
    "        # print(\"Title:\", result.title)\n",
    "\n",
    "    # Publisher\n",
    "    company = soup.find_all(attrs={\"data-qa\": \"company-name\"})\n",
    "    if len(company) > 0:\n",
    "        result.publisher = company[0].get_text().strip(\".- \") #\n",
    "    else:\n",
    "        item = soup.find(\"div\", {\"class\": \"brandLogoPrivate_dnns4\"})\n",
    "        if item is not None:\n",
    "            result.publisher = \"Private\"\n",
    "    # print(\"Publisher:\", result.publisher)\n",
    "\n",
    "    # Details\n",
    "    item = soup.find(\"div\", {\"class\": \"is24-ex-details\"})\n",
    "    for part in item.find_all(\"div\", {\"class\": \"criteriagroup\"}):\n",
    "        # Address and region\n",
    "        apt_address = part.find_all(\"span\", {\"class\": \"block font-nowrap print-hide\"})\n",
    "        if result.address is None and len(apt_address) > 0:\n",
    "            value_str = apt_address[0].get_text().strip().strip(\",\")\n",
    "            result.address = value_str\n",
    "            # print(\"Address:\", value_str)\n",
    "        apt_region = part.find_all(\"span\", {\"class\": \"zip-region-and-country\"})\n",
    "        if result.region is None and len(apt_region) > 0:\n",
    "            value_str = apt_region[0].get_text().strip()\n",
    "            result.region = value_str\n",
    "            # print(\"Region:\", value_str)\n",
    "\n",
    "        # Price: Kaltmiete\n",
    "        apt_price_k = part.find_all(\"dd\", {\"class\": \"is24qa-kaltmiete\"})\n",
    "        if result.price_cold is None and len(apt_price_k) > 0:\n",
    "            value_str = apt_price_k[0].get_text().strip()\n",
    "            result.price_cold = value_from_str(value_str)\n",
    "            # print(\"Price Kaltmiete:\", value_str, result.price_cold)\n",
    "        # Price: Gesamtmiete (warmmiete)\n",
    "        apt_price_w = part.find_all(\"dd\", {\"class\": \"is24qa-gesamtmiete\"})\n",
    "        if result.price_warm is None and len(apt_price_w) > 0:\n",
    "            value_str = apt_price_w[0].get_text().strip()\n",
    "            result.price_warm = value_from_str(value_str)\n",
    "            # print(\"Price Warmmiete:\", value_str, result.price_warm)\n",
    "        # Price: Geschätzte Gesamtmiete (warmmiete)\n",
    "        apt_price_w2 = part.find_all(\"dd\", {\"class\": \"is24qa-geschaetzte-gesamtmiete\"})\n",
    "        if result.price_warm is None and len(apt_price_w2) > 0:\n",
    "            value_str = apt_price_w2[0].get_text().strip()\n",
    "            result.price_warm = value_from_str(value_str)\n",
    "            # print(\"Price Geschätzte Warmmiete:\", value_str, result.price_warm)\n",
    "\n",
    "        # Type:\n",
    "        apt_type = part.find_all(\"dd\", {\"class\": \"is24qa-typ\"})\n",
    "        if result.apt_type is None and len(apt_type) > 0:\n",
    "            value_str = apt_type[0].get_text().strip()\n",
    "            result.apt_type = value_str\n",
    "            # print(\"Type:\", result.apt_type)\n",
    "\n",
    "        # Etage\n",
    "        apt_etage = part.find_all(\"dd\", {\"class\": \"is24qa-etage\"})\n",
    "        if result.floor is None and len(apt_etage) > 0:\n",
    "            value_str = apt_etage[0].get_text().strip()\n",
    "            values = value_str.split(\" \")  # \"5 von 8\" => 5, 8\n",
    "            if \"von\" in value_str and len(values) == 3:\n",
    "                result.floor = value_from_str(values[0])\n",
    "                result.floor_max = value_from_str(values[2])\n",
    "            elif len(values) == 1:\n",
    "                result.floor = value_from_str(values[0])\n",
    "            # print(\"Etage:\", result.floor, \"/\", result.floor_max)\n",
    "\n",
    "        # Surface\n",
    "        apt_area = part.find_all(\"dd\", {\"class\": \"is24qa-wohnflaeche-ca\"})\n",
    "        if result.area is None and len(apt_area) > 0:\n",
    "            value_str = apt_area[0].get_text().strip()\n",
    "            result.area = value_from_str_float(value_str)\n",
    "            # print(\"Area:\", result.area, value_str)\n",
    "\n",
    "        # Rooms\n",
    "        apt_rooms = part.find_all(\"dd\", {\"class\": \"is24qa-zimmer\"})\n",
    "        if result.rooms is None and len(apt_rooms) > 0:\n",
    "            value_str = apt_rooms[0].get_text().strip()\n",
    "            result.rooms = value_from_str(value_str)\n",
    "            # print(\"Rooms:\", result.rooms)\n",
    "\n",
    "        # Kaution\n",
    "        apt_kaution = part.find_all(\"div\", {\"class\": \"is24qa-kaution-o-genossenschaftsanteile\"})\n",
    "        if result.deposit is None and len(apt_kaution) > 0:\n",
    "            value_str = apt_kaution[0].get_text().strip()\n",
    "            result.deposit = value_str\n",
    "            # print(\"Kaution:\", value_str, result.deposit)\n",
    "\n",
    "    # print(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--city\", default=\"\", help=\"City to parse\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    city_name = args.city\n",
    "    if city_name.lower() == \"berlin\":\n",
    "        city_url = url_berlin\n",
    "        Process(target=get_data, args=(city_name, city_url, 1, 30)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 30, 60)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 60, 90)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 90, 120)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 120, 150)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 150, 185)).start()\n",
    "    elif city_name.lower() == \"frankfurt\":\n",
    "        city_url = url_frankfurt\n",
    "        Process(target=get_data, args=(city_name, city_url, 1, 20)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 20, 40)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 40, 60)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 60, 80)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 80, 110)).start()\n",
    "    elif city_name.lower() == \"koeln\":\n",
    "        city_url = url_koeln\n",
    "        Process(target=get_data, args=(city_name, city_url, 1, 20)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 20, 40)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 40, 70)).start()\n",
    "    elif city_name.lower() == \"hamburg\":\n",
    "        city_url = url_hamburg\n",
    "        Process(target=get_data, args=(city_name, city_url, 1, 25)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 25, 50)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 50, 75)).start()\n",
    "    elif city_name.lower() == \"dresden\":\n",
    "        city_url = url_dresden\n",
    "        Process(target=get_data, args=(city_name, city_url, 1, 25)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 25, 50)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 50, 80)).start()\n",
    "    elif city_name.lower() == \"munchen\":\n",
    "        city_url = url_munchen\n",
    "        Process(target=get_data, args=(city_name, city_url, 1, 20)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 20, 40)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 40, 60)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 60, 80)).start()\n",
    "        time.sleep(35)\n",
    "        Process(target=get_data, args=(city_name, city_url, 80, 110)).start()\n",
    "    else:\n",
    "        print(f\"City {args.city} is not found\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
