{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Igor Sorochan DSU-31\n",
    "## Домашнее задание по теме «Коллаборативная фильтрация»\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    import surprise # Surprise focuses on collaborative filtering, \n",
    "    # which is a popular technique for building recommender systems based on user-item interactions.\n",
    "except:\n",
    "    !pip install scikit-surprise\n",
    "    import surprise\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from surprise import Reader, Dataset, SVD, SVDpp, BaselineOnly, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, NMF, SlopeOne, CoClustering\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, train_test_split\n",
    "from surprise import accuracy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fUF83M0uHXwVfSxQ66uZ3g.png)\n",
    "\n",
    "* In the context of recommendation systems and matrix factorization, factorization refers to the process of decomposing a matrix into two lower-rank matrices. Specifically, when applying matrix factorization to a user-item interaction matrix, such as the ratings matrix in a collaborative filtering approach, the goal is to find lower-dimensional representations of users and items that capture their latent factors or features.\n",
    "\n",
    "* The factorization process aims to discover latent factors that explain the observed user-item interactions. Each user and item is represented as a vector of latent factors, and the dot product of these vectors estimates the missing or unknown ratings in the matrix. By factorizing the matrix, we can reduce its dimensionality and approximate the original matrix with a lower-rank approximation.\n",
    "\n",
    "* Singular Value Decomposition (SVD) is a popular matrix factorization technique used in recommendation systems. It decomposes the user-item interaction matrix into three matrices: U (user factors), Σ (singular values or weights), and V^T (item factors). By selecting a lower number of latent factors, we can approximate the original matrix using a subset of the singular values and their corresponding factors.\n",
    "\n",
    "* The factorization process allows the model to learn the underlying patterns and relationships in the data, capturing the user preferences and item characteristics. These latent factors can then be used to predict missing ratings or make personalized recommendations for users based on their similarities to other users or items in the latent factor space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?Dataset.load_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movielens-1m dataset (download it if needed).\n",
    "# Dataset.load_builtin(name='ml-1m', prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UserID::Gender::Age::Occupation::Zip-code\n",
    "users = pd.read_csv(\"/Users/velo1/SynologyDrive/GIT_syno/data/ml-1m/users.dat\", sep=\"::\", \n",
    "    header=None, names=[\"userId\", \"Gender\", \"Age\", \"Occupation\",\"Zip-code\"], engine=\"python\")\n",
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"/Users/velo1/SynologyDrive/GIT_syno/data/ml-1m/ratings.dat\", sep=\"::\", \n",
    "    header=None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"], engine=\"python\")\n",
    "ratings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_rating:  1 max_rating:  5\n"
     ]
    }
   ],
   "source": [
    "min_rating = ratings.rating.min()\n",
    "max_rating = ratings.rating.max()\n",
    "print(\"min_rating: \", min_rating, \"max_rating: \", max_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3883, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                    Title                        Genres\n",
       "0        1         Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3  Grumpier Old Men (1995)                Comedy|Romance"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MovieID::Title::Genres\n",
    "movies = pd.read_csv(\"/Users/velo1/SynologyDrive/GIT_syno/data/ml-1m/movies.dat\", sep=\"::\",\n",
    "    header=None, names=[\"movieId\", \"Title\", \"Genres\"], engine=\"python\", encoding=\"latin-1\")\n",
    "print(movies.shape)\n",
    "movies.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x13cee5d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(line_format='user item rating timestamp', sep='::', rating_scale=(min_rating, max_rating))\n",
    "# reader = Reader(line_format=reader_cols, sep='::', rating_scale=(1, 5))\n",
    "data = Dataset.load_from_file(\"/Users/velo1/SynologyDrive/GIT_syno/data/ml-1m/ratings.dat\", reader=reader)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm SVD is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  11%|█         | 1/9 [00:23<03:08, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm BaselineOnly is running...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  22%|██▏       | 2/9 [00:40<02:19, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm KNNBasic is running...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  33%|███▎      | 3/9 [08:55<23:40, 236.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm KNNWithMeans is running...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  44%|████▍     | 4/9 [16:51<27:35, 331.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm KNNWithZScore is running...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  56%|█████▌    | 5/9 [25:32<26:38, 399.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm KNNBaseline is running...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  67%|██████▋   | 6/9 [34:12<22:01, 440.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm NMF is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  78%|███████▊  | 7/9 [34:46<10:14, 307.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm SlopeOne is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms:  89%|████████▉ | 8/9 [38:51<04:47, 287.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm CoClustering is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running algorithms: 100%|██████████| 9/9 [39:18<00:00, 262.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Algorithm: SVD\n",
      "Mean RMSE: 0.8737926799855067\n",
      "-------\n",
      "Algorithm: BaselineOnly\n",
      "Mean RMSE: 0.9086413089573007\n",
      "-------\n",
      "Algorithm: KNNBasic\n",
      "Mean RMSE: 0.9227537773868983\n",
      "-------\n",
      "Algorithm: KNNWithMeans\n",
      "Mean RMSE: 0.9293471668748319\n",
      "-------\n",
      "Algorithm: KNNWithZScore\n",
      "Mean RMSE: 0.930665043371406\n",
      "-------\n",
      "Algorithm: KNNBaseline\n",
      "Mean RMSE: 0.8950032989274754\n",
      "-------\n",
      "Algorithm: NMF\n",
      "Mean RMSE: 0.9162796975027663\n",
      "-------\n",
      "Algorithm: SlopeOne\n",
      "Mean RMSE: 0.9067378582381183\n",
      "-------\n",
      "Algorithm: CoClustering\n",
      "Mean RMSE: 0.9156466007593915\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algos = [\n",
    "    SVD(),\n",
    "    BaselineOnly(),\n",
    "    KNNBasic(),\n",
    "    KNNWithMeans(),\n",
    "    KNNWithZScore(),\n",
    "    KNNBaseline(),\n",
    "    NMF(),\n",
    "    SlopeOne(),\n",
    "    CoClustering(),\n",
    "]\n",
    "results = {}\n",
    "algo_results = {}\n",
    "for algo in tqdm(algos, desc=\"Running algorithms\"):\n",
    "    algo_name = algo.__class__.__name__\n",
    "    print(f\"Algorithm {algo_name} is running...\")\n",
    "    algo_results[algo_name] = cross_validate(\n",
    "        algo,  #  Algorithm predicting the baseline estimate for given user and item.\n",
    "        data,  # data to be used for cross-validation\n",
    "        verbose=False,  # print the performance metric\n",
    "        cv=5,  # 5-fold cross validation\n",
    "        measures=[\"RMSE\", \"MAE\"],\n",
    "        n_jobs=-1,  # use all available CPU cores for parallel processing.\n",
    "        pre_dispatch=\"2*n_jobs\",  # twice the number of available CPU cores.\n",
    "        return_train_measures=True,  # return the train error measures.\n",
    "    )\n",
    "\n",
    "    mean_rmse = algo_results[algo_name]['test_rmse'].mean()\n",
    "    results[algo_name] = {'mean_rmse': mean_rmse}\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "for algo, result in results.items():\n",
    "    print(f\"Algorithm: {algo}\")\n",
    "    print(f\"Mean RMSE: {result['mean_rmse']}\")\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(results)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39msort_values(\u001b[39m\"\u001b[39m\u001b[39mmean_rmse\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstyle\u001b[39m.\u001b[39mbackground_gradient(cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcoolwarm\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(results).T.sort_values(\"mean_rmse\").style.background_gradient(cmap=\"coolwarm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular value decomposition (SVD) algorithm is the best algorithm for the given dataset.  \n",
    "It is a matrix factorization technique that is usually very effective for recommender systems.  \n",
    "It is a collaborative filtering algorithm that decomposes the user-item matrix by keeping the most important latent features that capture the majority of the item ratings.  \n",
    "It is a popular algorithm for recommender systems because it can deal with the sparsity of the user-item matrix by extracting the most important latent features related to the users and items.  \n",
    "\n",
    "Let's try to fine tune the SVD algorithm to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  10 | elapsed:    8.7s remaining:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    9.8s remaining:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:   10.1s remaining:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   10.9s remaining:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   11.7s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   12.5s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  10 | elapsed:   13.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.1s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    # \"n_epochs\": [100],\n",
    "    # \"lr_all\": [0.002],\n",
    "    # \"reg_all\": [0.4],\n",
    "    \"n_factors\": [39],\n",
    "    \"random_state\": [42],\n",
    "    \"init_mean\": [0.1],\n",
    "    \"init_std_dev\": [0.045, 0.047],\n",
    "    \"verbose\": [False],\n",
    "}\n",
    "gs_svd = GridSearchCV(algo_class=SVD, param_grid=param_grid, measures=[\"rmse\", \"mae\"], cv=5, return_train_measures=False,\n",
    "                  n_jobs=-1, joblib_verbose=100, refit=True, pre_dispatch='2*n_jobs',)\n",
    "\n",
    "gs_svd.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862735062956751\n",
      "{'n_factors': 39, 'random_state': 42, 'init_mean': 0.1, 'init_std_dev': 0.047, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(gs_svd.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_svd.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8607  0.8627  0.8626  0.8621  0.8584  0.8613  0.0016  \n",
      "MAE (testset)     0.6714  0.6721  0.6727  0.6719  0.6691  0.6715  0.0012  \n",
      "RMSE (trainset)   0.7581  0.7573  0.7590  0.7570  0.7573  0.7577  0.0007  \n",
      "MAE (trainset)    0.5939  0.5932  0.5944  0.5930  0.5932  0.5936  0.0005  \n",
      "Fit time          300.36  298.51  299.11  297.87  300.04  299.18  0.93    \n",
      "Test time         58.61   60.41   58.85   59.09   61.06   59.60   0.96    \n"
     ]
    }
   ],
   "source": [
    "res = cross_validate(\n",
    "    SVDpp(),                    # SVD is singular value decomposition (SVD) algorithm.\n",
    "    data,                       # data to be used for cross-validation         \n",
    "    verbose=True,               # print the performance metric\n",
    "    cv=5,                       # 5-fold cross validation\n",
    "    measures=[\"RMSE\", \"MAE\"],\n",
    "    n_jobs=-1,                  # use all available CPU cores for parallel processing.\n",
    "    pre_dispatch=\"2*n_jobs\",    # twice the number of available CPU cores.\n",
    "    return_train_measures=False, # return the train error measures.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVDpp algorithm is an extension of SVD that takes into account implicit ratings.  \n",
    "Even without hyperparameter tuning, SVDpp is better than SVD on the MovieLens dataset.  \n",
    "\n",
    "Let's try to fine tune the SVDpp algorithm to get the best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "785.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.79s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.80s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.81s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.81s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.82s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.83s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.84s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.86s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.86s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.88s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.88s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.89s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "785.92s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    # \"n_epochs\": [100],\n",
    "    # \"lr_all\": [0.002],\n",
    "    # \"reg_all\": [0.4],\n",
    "    \"n_factors\": [39],\n",
    "    \"random_state\": [42],\n",
    "    \"init_mean\": [0.1],\n",
    "    \"init_std_dev\": [0.045],\n",
    "    \"verbose\": [False],\n",
    "}\n",
    "gs_svdpp = GridSearchCV(algo_class=SVDpp, param_grid=param_grid, measures=[\"rmse\", \"mae\"], cv=5, return_train_measures=False,\n",
    "                  n_jobs=-1, joblib_verbose=100, refit=True, pre_dispatch='2*n_jobs',)\n",
    "\n",
    "gs_svdpp.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8588097586602299\n",
      "{'n_factors': 39, 'random_state': 42, 'init_mean': 0.1, 'init_std_dev': 0.045, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(gs_svdpp.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_svdpp.best_params[\"rmse\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to find a list of the movies that a particular user has not seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_recommendation(model, user_id, ratings, movies, n_items):\n",
    "   # Get a list of all movie IDs from dataset\n",
    "   movie_ids = movies[\"movieId\"].unique()\n",
    " \n",
    "   # Get a list of all movie IDs that have been watched by user\n",
    "   movie_ids_user = ratings.loc[ratings[\"userId\"] == user_id, \"movieId\"]\n",
    "#    movie_ids_user = ratings[ratings[\"userId\"] == user_id][\"movieId\"]\n",
    "\n",
    "    # Get a list off all movie IDS that that have NOT been watched by user\n",
    "    # returns an array containing the values in movie_ids that are not present in movie_ids_user.\n",
    "   movie_ids_to_pred = np.setdiff1d(movie_ids, movie_ids_user) # setdiff1d: Find the set difference of two arrays.\n",
    " \n",
    "   # Apply a rating of 4 to all interactions (only to match the Surprise dataset format)\n",
    "   test_set = [[user_id, movie_id, 0] for movie_id in movie_ids_to_pred]\n",
    " \n",
    "   # Predict the ratings and generate recommendations\n",
    "   predictions = model.test(test_set)\n",
    "   pred_ratings = np.array([pred.est for pred in predictions])\n",
    "   print(f\"Top {n_items} item recommendations for user {user_id}:\")\n",
    "   print(f\"{'-' * 40}\")\n",
    "   # Rank top-n movies based on the predicted ratings\n",
    "   # -pred_ratings negates all the predicted ratings. This is done because the argsort() function sorts the array \n",
    "   # in ascending order by default, but we want to find the items with the highest ratings, \n",
    "   # so we need to sort them in descending order.\n",
    "   # [:n_items] slices the sorted indices to select only the first n_items indices, which represent the items \n",
    "   # with the highest predicted ratings.\n",
    "   index_max = (-pred_ratings).argsort()[:n_items] \n",
    "   for i in index_max:\n",
    "       movie_id = movie_ids_to_pred[i]\n",
    "       print(f'{movies[movies[\"movieId\"]==movie_id][\"Title\"].values[0]:<65}:{pred_ratings[i]:.2f}')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 item recommendations for user 4169:\n",
      "----------------------------------------\n",
      "Toy Story (1995)                                                 :3.58\n",
      "Twice Upon a Yesterday (1998)                                    :3.58\n",
      "Loss of Sexual Innocence, The (1999)                             :3.58\n",
      "Eternity and a Day (Mia eoniotita ke mia mera ) (1998)           :3.58\n",
      "It Conquered the World (1956)                                    :3.58\n",
      "Flying Saucer, The (1950)                                        :3.58\n",
      "Howling II: Your Sister Is a Werewolf (1985)                     :3.58\n",
      "Curse of Frankenstein, The (1957)                                :3.58\n",
      "Dracula (1958)                                                   :3.58\n",
      "Mummy's Ghost, The (1944)                                        :3.58\n"
     ]
    }
   ],
   "source": [
    "# define which user ID that we want to give recommendation\n",
    "userID = 4169\n",
    "# define how many top-n movies that we want to recommend\n",
    "n_items = 10\n",
    "# generate recommendation using the model that we have trained\n",
    "give_recommendation(gs_svd,userID,ratings,movies,n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.predict(4169, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695642    3789\n",
       "695643     571\n",
       "695644     574\n",
       "695645     575\n",
       "695646     577\n",
       "          ... \n",
       "697951    3784\n",
       "697952    3785\n",
       "697953    2047\n",
       "697954    3788\n",
       "697955    2049\n",
       "Name: movieId, Length: 2314, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids_user = ratings[ratings[\"userId\"] == 4169][\"movieId\"]\n",
    "# movies[movies[\"movieId\"].isin(movie_ids_user)][\"Title\"]\n",
    "movie_ids_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695642    3789\n",
       "695643     571\n",
       "695644     574\n",
       "695645     575\n",
       "695646     577\n",
       "          ... \n",
       "697951    3784\n",
       "697952    3785\n",
       "697953    2047\n",
       "697954    3788\n",
       "697955    2049\n",
       "Name: movieId, Length: 2314, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids_user = ratings.loc[ratings[\"userId\"] == 4169, \"movieId\"]\n",
    "movie_ids_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695642</th>\n",
       "      <td>4169</td>\n",
       "      <td>3789</td>\n",
       "      <td>5</td>\n",
       "      <td>965333672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697686</th>\n",
       "      <td>4169</td>\n",
       "      <td>2732</td>\n",
       "      <td>5</td>\n",
       "      <td>971579309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696096</th>\n",
       "      <td>4169</td>\n",
       "      <td>265</td>\n",
       "      <td>5</td>\n",
       "      <td>971582264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697334</th>\n",
       "      <td>4169</td>\n",
       "      <td>475</td>\n",
       "      <td>5</td>\n",
       "      <td>975803853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697335</th>\n",
       "      <td>4169</td>\n",
       "      <td>477</td>\n",
       "      <td>5</td>\n",
       "      <td>973310837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696591</th>\n",
       "      <td>4169</td>\n",
       "      <td>1924</td>\n",
       "      <td>1</td>\n",
       "      <td>971580320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696110</th>\n",
       "      <td>4169</td>\n",
       "      <td>1884</td>\n",
       "      <td>1</td>\n",
       "      <td>976588147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695927</th>\n",
       "      <td>4169</td>\n",
       "      <td>2450</td>\n",
       "      <td>1</td>\n",
       "      <td>971581624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697817</th>\n",
       "      <td>4169</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>978663954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696799</th>\n",
       "      <td>4169</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>978663154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2314 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating  timestamp\n",
       "695642    4169     3789       5  965333672\n",
       "697686    4169     2732       5  971579309\n",
       "696096    4169      265       5  971582264\n",
       "697334    4169      475       5  975803853\n",
       "697335    4169      477       5  973310837\n",
       "...        ...      ...     ...        ...\n",
       "696591    4169     1924       1  971580320\n",
       "696110    4169     1884       1  976588147\n",
       "695927    4169     2450       1  971581624\n",
       "697817    4169      519       1  978663954\n",
       "696799    4169     1999       1  978663154\n",
       "\n",
       "[2314 rows x 4 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings[\"userId\"] == 4169].sort_values(by=\"rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "4169    2314\n",
       "1680    1850\n",
       "4277    1743\n",
       "1941    1595\n",
       "1181    1521\n",
       "889     1518\n",
       "3618    1344\n",
       "2063    1323\n",
       "1150    1302\n",
       "1015    1286\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.groupby(\"userId\")[\"rating\"].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 3)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
